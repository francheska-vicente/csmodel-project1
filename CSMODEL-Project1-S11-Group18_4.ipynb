{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "Import `numpy`, `pandas`, `matplotlib.pyplot`, and `scipy.stats`.\n",
    "\n",
    "- `numpy` contains a large collection of mathematical functions\n",
    "- `pandas` is a software library for Python that is designed for data manipulation and data analysis\n",
    "- `matplotlib.pyplot` contains functions to create interactive plots\n",
    "- `scipy.stats` is a module that contains a variety of statistical functions. \n",
    "\n",
    "We will be using these four libraries in this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Representation\n",
    "This dataset contains the Top 500 most powerful non-distributed computer systems or supercomputers in the world. \n",
    "\n",
    "To objectively rank the performance of these computer systems, the **LINPACK Benchmark** is used. The benchmark measures the floating-point rate of execution of a computer where the computer is tasked to solve a complex system of linear equations. While it is not a complete indicator of the overall performance of a computer system, it is still accurate in estimating peak performance.\n",
    "\n",
    "Only general-purpose systems are included in this list, which are supercomputers that can solve a range of scientific problems; this avoids any supercomputers being created only to solve the LINPACK Benchmark.\n",
    "\n",
    "### Collection Process\n",
    "The TOP500 project dates back to 1993 and since then, the list is compiled twice a year through online submissions and other published statistical lists.\n",
    "\n",
    "Internet users and computer vendors may choose to submit the necessary information about a system online. Naturally, the data is carefully verified with the original manufacturers and in some cases, contact is established with the installation site. All of the data is collected and verified by the authors with the help of various contributors, like high-performance computer experts, computational scientists, and manufacturers. Any misinformation or corrections can also be reported to their website.\n",
    "\n",
    "### Structure of the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was provided as a `.csv` file, which will be loaded into the notebook using the [`read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) function. The [`info`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html) function is then called to display information about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 37 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Rank                             500 non-null    int64  \n",
      " 1   Previous Rank                    456 non-null    float64\n",
      " 2   First Appearance                 500 non-null    int64  \n",
      " 3   First Rank                       500 non-null    int64  \n",
      " 4   Name                             315 non-null    object \n",
      " 5   Computer                         500 non-null    object \n",
      " 6   Site                             500 non-null    object \n",
      " 7   Manufacturer                     500 non-null    object \n",
      " 8   Country                          500 non-null    object \n",
      " 9   Year                             500 non-null    int64  \n",
      " 10  Segment                          500 non-null    object \n",
      " 11  Total Cores                      500 non-null    object \n",
      " 12  Accelerator/Co-Processor Cores   149 non-null    object \n",
      " 13  Rmax [TFlop/s]                   500 non-null    object \n",
      " 14  Rpeak [TFlop/s]                  500 non-null    object \n",
      " 15  Nmax                             495 non-null    object \n",
      " 16  Nhalf                            12 non-null     object \n",
      " 17  HPCG [TFlop/s]                   73 non-null     object \n",
      " 18  Power (kW)                       189 non-null    object \n",
      " 19  Power Source                     189 non-null    object \n",
      " 20  Power Efficiency [GFlops/Watts]  189 non-null    float64\n",
      " 21  Architecture                     500 non-null    object \n",
      " 22  Processor                        500 non-null    object \n",
      " 23  Processor Technology             500 non-null    object \n",
      " 24  Processor Speed (MHz)            500 non-null    object \n",
      " 25  Operating System                 500 non-null    object \n",
      " 26  OS Family                        500 non-null    object \n",
      " 27  Accelerator/Co-Processor         500 non-null    object \n",
      " 28  Cores per Socket                 500 non-null    int64  \n",
      " 29  Processor Generation             500 non-null    object \n",
      " 30  System Model                     500 non-null    object \n",
      " 31  System Family                    500 non-null    object \n",
      " 32  Interconnect Family              500 non-null    object \n",
      " 33  Interconnect                     500 non-null    object \n",
      " 34  Continent                        500 non-null    object \n",
      " 35  Site ID                          500 non-null    object \n",
      " 36  System ID                        500 non-null    int64  \n",
      "dtypes: float64(2), int64(6), object(29)\n",
      "memory usage: 144.7+ KB\n"
     ]
    }
   ],
   "source": [
    "supercom_df = pd.read_csv(\"TOP500.csv\")\n",
    "supercom_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the dataset represents a single observation without any duplicate observations. According to the information shown above, there are 500 observations in the dataset, each one corresponding to a single supercomputer. \n",
    "\n",
    "Each column in the dataset refers to the variables an observation has. There are 37 variables in the dataset, which are the properties and information related to a supercomputer and its performance.\n",
    "\n",
    "### Variables\n",
    "The [`columns`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.columns.html) property of the `DataFrame` is called to see the list of variables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rank', 'Previous Rank', 'First Appearance', 'First Rank', 'Name',\n",
       "       'Computer', 'Site', 'Manufacturer', 'Country', 'Year', 'Segment',\n",
       "       'Total Cores', 'Accelerator/Co-Processor Cores', 'Rmax [TFlop/s]',\n",
       "       'Rpeak [TFlop/s]', 'Nmax', 'Nhalf', 'HPCG [TFlop/s]', 'Power (kW)',\n",
       "       'Power Source', 'Power Efficiency [GFlops/Watts]', 'Architecture',\n",
       "       'Processor', 'Processor Technology', 'Processor Speed (MHz)',\n",
       "       'Operating System', 'OS Family', 'Accelerator/Co-Processor',\n",
       "       'Cores per Socket', 'Processor Generation', 'System Model',\n",
       "       'System Family', 'Interconnect Family', 'Interconnect', 'Continent',\n",
       "       'Site ID', 'System ID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supercom_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the descriptions of each of the variables used in the data set:\n",
    "- **`Rank`**: position of the supercomputer in the TOP500 ranking system\n",
    "- **`Previous Rank`**: position of the supercomputer in the previous edition of the TOP500 list, *if the supercomputer appeared in the previous edition*\n",
    "- **`First Appearance`**: the edition of the TOP500 list where the supercomputer first appeared\n",
    "- **`First Rank`**: position of the supercomputer in the TOP500 ranking system in its first appearance in the list\n",
    "- **`Name`**: name of the supercomputer, *if the supercomputer has a name*\n",
    "- **`Computer`**: type of the supercomputer as indicated by the manufacturer or vendor \n",
    "- **`Site`**: current location of the supercomputer\n",
    "- **`Manufacturer`**: manufacturer of the supercomputer\n",
    "- **`Country`**: current country where the supercomputer is located\n",
    "- **`Year`**: year of installation or last major update of the supercomputer\n",
    "- **`Segment`**: purpose of the supercomputer\n",
    "- **`Total Cores`**: number of cores that the supercomputer uses\n",
    "- **`Accelerator/Co-Processor Cores`**: number of accelerator/co-processor cores that the supercomputer uses, *if the supercomputer uses one*\n",
    "- **`Rmax [TFlop/s]`**: maximum LINPACK performance achieved by the supercomputer in TFlops (one trillion floating point operations per second)\n",
    "- **`Rpeak [TFlop/s]`**: theoretical peak performance of the supercomputer\n",
    "- **`Nmax`**: number of equations solved by the supercomputer to achieve Rmax, *if submitted*\n",
    "- **`Nhalf`**: half of Nmax / half the number of equations solved to achieve Rmax, *if computed*\n",
    "- **`HPCG [TFlop/s]`**: maximum HPCG performance achieved by the supercomputer in TFlops, *if the benchmark was used and the result was submitted*\n",
    "- **`Power (kW)`**: electric power consumption of the supercomputer in kilowatts, *if power source was submitted*\n",
    "- **`Power Source`**: whether the information about the power source was submitted or not, *blank if not submitted*\n",
    "- **`Power Efficiency [GFlops/Watts]`**: efficiency of the power consumption of the supercomputer, *if power source was submitted*\n",
    "- **`Architecture`**: type of architechture used by the supercomputer\n",
    "- **`Processor`**: model of the processor used by the supercomputer\n",
    "- **`Processor Technology`**:  used by the supercomputer\n",
    "- **`Processor Speed (MHz)`**: speed of the processor used by the supercomputer\n",
    "- **`Operating System`**: specific version of the operating system used by the supercomputer\n",
    "- **`OS Family`**: family of the operating system used by the supercomputer\n",
    "- **`Accelerator/Co-Processor`**: model of the accelerator or co-processor used by the supercomputer, *`None` if the supercomputer does not use one*\n",
    "- **`Cores per Socket`**: number of cores the supercomputer has per socket\n",
    "- **`Processor Generation`**: generation of the supercomputer's processor\n",
    "- **`System Model`**: specific model of the supercomputer's system\n",
    "- **`System Family`**: family of the supercomputer's system\n",
    "- **`Interconnect Family`**: family of data interconnect used by the supercomputer\n",
    "- **`Interconnect`**: specific model of data interconnect used by the supercomputer\n",
    "- **`Continent`**: current continent where the supercomputer is located\n",
    "- **`Site ID`**: id of the current site of the supercomputer\n",
    "- **`System ID`**: id of the supercomputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "To be able to explore our data set correctly, data cleaning should be done to remove any inconsistencies that might cause the data analysis to be done incorrectly. In this notebook, the variables that would be utilized are: (1)**`Total Cores`**, (2)**`Rmax [TFlop/s]`**, (3)**`Rpeak [TFlop/s]`**, (4)**`Rank`**, (5)**`Segment`**, (6)**`Continent`**, and (7)**`Processor Technology`**. Only these columns/variables would be checked and if needed, cleaned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Total Cores` variable\n",
    "Since the `Total Cores` variable refers to the number of cores that the supercomputer uses, we are expecting whole numbers as our values for this column. This also implies that there should be no null values in this column as any computer requires cores to function. \n",
    "\n",
    "If we look at the data type of this column using the `info` function above, we would see that the data type it returned is object. Since `Total Cores` is categorized as numerical data, it should be represented as an integer instead so the data may be graphed later on. Casting a pandas object to another data type (in this instance, into an integer) can be done using the [`astype`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html) function.\n",
    "\n",
    "However, if we directly try to convert the data type of this column to an int, it would result to a ValueError; this is because it received the correct data type (i.e. object), but had an incorrect value (i.e. there are commas). Thus, we would need to use the [`replace`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html) function in order to remove the commas (\"replacing\" these commas with nothing would equate to us removing these commas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "supercom_df['Total Cores'] = supercom_df['Total Cores'].replace(',','', regex=True)\n",
    "supercom_df['Total Cores'] = supercom_df['Total Cores'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling the [`info`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html) function again, the difference between the data type of `Total Cores` before and after the [`astype`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html) function was called can be seen. It changed from object to int32, which means that the `Total Cores` variable is now a 32-bit integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 37 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Rank                             500 non-null    int64  \n",
      " 1   Previous Rank                    456 non-null    float64\n",
      " 2   First Appearance                 500 non-null    int64  \n",
      " 3   First Rank                       500 non-null    int64  \n",
      " 4   Name                             315 non-null    object \n",
      " 5   Computer                         500 non-null    object \n",
      " 6   Site                             500 non-null    object \n",
      " 7   Manufacturer                     500 non-null    object \n",
      " 8   Country                          500 non-null    object \n",
      " 9   Year                             500 non-null    int64  \n",
      " 10  Segment                          500 non-null    object \n",
      " 11  Total Cores                      500 non-null    int32  \n",
      " 12  Accelerator/Co-Processor Cores   149 non-null    object \n",
      " 13  Rmax [TFlop/s]                   500 non-null    object \n",
      " 14  Rpeak [TFlop/s]                  500 non-null    object \n",
      " 15  Nmax                             495 non-null    object \n",
      " 16  Nhalf                            12 non-null     object \n",
      " 17  HPCG [TFlop/s]                   73 non-null     object \n",
      " 18  Power (kW)                       189 non-null    object \n",
      " 19  Power Source                     189 non-null    object \n",
      " 20  Power Efficiency [GFlops/Watts]  189 non-null    float64\n",
      " 21  Architecture                     500 non-null    object \n",
      " 22  Processor                        500 non-null    object \n",
      " 23  Processor Technology             500 non-null    object \n",
      " 24  Processor Speed (MHz)            500 non-null    object \n",
      " 25  Operating System                 500 non-null    object \n",
      " 26  OS Family                        500 non-null    object \n",
      " 27  Accelerator/Co-Processor         500 non-null    object \n",
      " 28  Cores per Socket                 500 non-null    int64  \n",
      " 29  Processor Generation             500 non-null    object \n",
      " 30  System Model                     500 non-null    object \n",
      " 31  System Family                    500 non-null    object \n",
      " 32  Interconnect Family              500 non-null    object \n",
      " 33  Interconnect                     500 non-null    object \n",
      " 34  Continent                        500 non-null    object \n",
      " 35  Site ID                          500 non-null    object \n",
      " 36  System ID                        500 non-null    int64  \n",
      "dtypes: float64(2), int32(1), int64(6), object(28)\n",
      "memory usage: 142.7+ KB\n"
     ]
    }
   ],
   "source": [
    "supercom_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the values of this variable using the [`unique`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.unique.html) function. Using this function, we can also recheck if all our values for this column are whole numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7630848,  2414592,  1572480, 10649600,   555520,  4981760,\n",
       "         449280,   669760,   448448,   672520,   347776,   387872,\n",
       "         979072,   391680,   305856,   698880,   288288,   291024,\n",
       "         276480,   622336,   570020,   556104,   253600,   561408,\n",
       "         367024,   127488,   204032,   170352,   130000,   294912,\n",
       "         135828,   174720,    34560,   169920,   107568,   241920,\n",
       "         197120,   280320,    99600,   110592,   153216,   211816,\n",
       "         114480,   100096,   241108,   120296,    99792,   135792,\n",
       "         127520,   196608,   124416,   169728,   103680,   220800,\n",
       "          88400,    79560,    75600,   144900,   172032,    41664,\n",
       "          72000,    93960,    91936,   163840,    81600,    76608,\n",
       "          71424,    70416,   131072,    79488,   145920,   126468,\n",
       "         155150,   119232,    65208,    85568,    70560,    86400,\n",
       "          80640,    72800,    63360,    85560,   215040,    38400,\n",
       "          67584,   124200,    60512,   113832,    62400,    55296,\n",
       "          60480,    71232,   110160,    59136,   225984,   152692,\n",
       "          76000,   128000,    53568,    63840,   122400,    61120,\n",
       "          99072,    73600,    64512,    49056,    94160,    79104,\n",
       "          86016,    89856,    54560,    68000,    67200,    66400,\n",
       "          59976,    37920,    52920,    65600,    53200,    47808,\n",
       "          64800,    69120,    43200,    95472,    64000,    50400,\n",
       "          14848,    66000,    64320,    83592,   186368,    23040,\n",
       "          50816,   194616,    85824,    61440,   100064,    61200,\n",
       "          91648,    64384,    60000,    73920,    48128,    59200,\n",
       "         115200,    58800,   113600,    69600,    58000,    58560,\n",
       "          46080,   112000,    19840,   153600,    48160,    53760,\n",
       "          53300,    56000,    49920,   108800,    37440,    55104,\n",
       "          47320,    72480,    40560,    40800,    50176,    76032,\n",
       "          54000,    52000,    49800,    73440,   121920,    94976,\n",
       "          96640,    44200,    44720,    40960,    50000,    40000,\n",
       "         166304,    44032,    32160,    59760,    52320,    44160,\n",
       "          49200,    53040,    48000,    55440,    48880,    41280,\n",
       "         110880,    42312,    39760,    36864,   116600,   520000,\n",
       "          47200,    41472,    60800,    89600,    45152,    49432,\n",
       "          66304,    47600,    53280,    58112,    60240,    51504,\n",
       "          40320,    57200,    49680,    46200,    65268,    56800,\n",
       "          47040,   173680,    70272,    28240,    44000,    46480,\n",
       "          33856,    31104,    55040,    83200,   143640,   116200,\n",
       "          66080,    41760,    44100,    54240,    30600,    36000,\n",
       "         110080,    33840,    67456,   105000,    38552,    33120,\n",
       "          80000,    99360,    34800,    35280,  2312800,    97920,\n",
       "          32400,   118400,    35200,    39680,    31680,    57600,\n",
       "          28800,    48960,    55728,    30960,   100800,    31524,\n",
       "           1664,    78400,    37632,    43520,    42752,   118080,\n",
       "          32144,    59520,    37600,    27768,    86800,    33600,\n",
       "          31360,    62944,    27520,    36800,    88800,    92000,\n",
       "          34400,    30576,    38880,    84000,    82880,    53352,\n",
       "          29792,    29400,    79520,    42840,    33000,    76896,\n",
       "          28224,    26180,    82000,    32800,    30240,    82800,\n",
       "          52080,    73584,    25232,    78720,    78000,    44016,\n",
       "          28000,    32640,    32000,    59392,    34000,    30624,\n",
       "          49896,    54648,    77184,    25920,    82752,    24000,\n",
       "          35712,    26400,    27200,    30000,    29920])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supercom_df['Total Cores'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are now assured that the values for this columns are all whole numbers, we just need to check if there are observations that contains a NaN/null value. This can be done using the [`isnull`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.isnull.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supercom_df['Total Cores'].isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no NaN/null value for this column, we can now move to the next variable as we know that the `Total Cores` variable is clean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Rmax [TFlop/s]` variable\n",
    "For the `Rmax [TFlop/s]` variable, we are expecting a floating point value. Since this value is required for all supercomputers compiled in this list, it is expected that there are no observations with a NaN/null value. \n",
    "\n",
    "However, just like the `Total Cores` variable, the `Rmax [TFlop/s]` column is stored as an object and not a float. Like earlier, we would need to convert the column to a float using the [`astype`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html) function and use the  [`replace`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html) function to remove any commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "supercom_df['Rmax [TFlop/s]'] = supercom_df['Rmax [TFlop/s]'].replace(',','', regex=True)\n",
    "supercom_df['Rmax [TFlop/s]'] = supercom_df['Rmax [TFlop/s]'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the [`info`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html) function, we could see that the data type of the `Rmax [TFlop/s]` column has changed to float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 37 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Rank                             500 non-null    int64  \n",
      " 1   Previous Rank                    456 non-null    float64\n",
      " 2   First Appearance                 500 non-null    int64  \n",
      " 3   First Rank                       500 non-null    int64  \n",
      " 4   Name                             315 non-null    object \n",
      " 5   Computer                         500 non-null    object \n",
      " 6   Site                             500 non-null    object \n",
      " 7   Manufacturer                     500 non-null    object \n",
      " 8   Country                          500 non-null    object \n",
      " 9   Year                             500 non-null    int64  \n",
      " 10  Segment                          500 non-null    object \n",
      " 11  Total Cores                      500 non-null    int32  \n",
      " 12  Accelerator/Co-Processor Cores   149 non-null    object \n",
      " 13  Rmax [TFlop/s]                   500 non-null    float64\n",
      " 14  Rpeak [TFlop/s]                  500 non-null    object \n",
      " 15  Nmax                             495 non-null    object \n",
      " 16  Nhalf                            12 non-null     object \n",
      " 17  HPCG [TFlop/s]                   73 non-null     object \n",
      " 18  Power (kW)                       189 non-null    object \n",
      " 19  Power Source                     189 non-null    object \n",
      " 20  Power Efficiency [GFlops/Watts]  189 non-null    float64\n",
      " 21  Architecture                     500 non-null    object \n",
      " 22  Processor                        500 non-null    object \n",
      " 23  Processor Technology             500 non-null    object \n",
      " 24  Processor Speed (MHz)            500 non-null    object \n",
      " 25  Operating System                 500 non-null    object \n",
      " 26  OS Family                        500 non-null    object \n",
      " 27  Accelerator/Co-Processor         500 non-null    object \n",
      " 28  Cores per Socket                 500 non-null    int64  \n",
      " 29  Processor Generation             500 non-null    object \n",
      " 30  System Model                     500 non-null    object \n",
      " 31  System Family                    500 non-null    object \n",
      " 32  Interconnect Family              500 non-null    object \n",
      " 33  Interconnect                     500 non-null    object \n",
      " 34  Continent                        500 non-null    object \n",
      " 35  Site ID                          500 non-null    object \n",
      " 36  System ID                        500 non-null    int64  \n",
      "dtypes: float64(3), int32(1), int64(6), object(27)\n",
      "memory usage: 142.7+ KB\n"
     ]
    }
   ],
   "source": [
    "supercom_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the `Rmax [TFlop/s]` column has been changed to float, we now only have to check if the column contains NaN/null values with the use of the [`isnull`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.isnull.html) function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supercom_df['Rmax [TFlop/s]'].isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using the [`unique`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.unique.html) function, we can see if the all values are valid or if any default values are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([442010.  , 148600.  ,  94640.  ,  93014.59,  63460.  ,  61444.5 ,\n",
       "        44120.  ,  35450.  ,  23516.4 ,  22400.  ,  21640.  ,  21230.  ,\n",
       "        20158.7 ,  19880.  ,  19476.6 ,  19334.  ,  18200.  ,  17860.  ,\n",
       "        16592.  ,  14014.7 ,  13929.3 ,  13554.6 ,  12210.  ,  11965.5 ,\n",
       "        10680.7 ,   9444.  ,   9264.31,   9000.  ,   8339.  ,   8191.03,\n",
       "         8125.  ,   8124.48,   7892.7 ,   7683.36,   7483.73,   7257.  ,\n",
       "         7038.93,   6988.04,   6920.9 ,   6669.  ,   6617.8 ,   6470.8 ,\n",
       "         6316.03,   6177.73,   6162.  ,   5951.55,   5948.8 ,   5780.62,\n",
       "         5730.5 ,   5612.83,   5536.99,   5444.64,   5388.52,   5355.94,\n",
       "         5283.11,   5161.  ,   4880.46,   4850.66,   4788.19,   4724.79,\n",
       "         4619.  ,   4540.69,   4478.  ,   4376.  ,   4325.  ,   4299.33,\n",
       "         4289.85,   4281.  ,   4128.  ,   4101.  ,   4065.55,   4042.46,\n",
       "         3944.68,   3782.57,   3763.94,   3712.  ,   3700.15,   3665.72,\n",
       "         3608.62,   3599.66,   3577.  ,   3533.61,   3487.91,   3486.1 ,\n",
       "         3449.  ,   3371.  ,   3318.95,   3307.  ,   3243.41,   3241.24,\n",
       "         3221.4 ,   3188.  ,   3161.  ,   3158.11,   3157.  ,   3148.38,\n",
       "         3143.52,   3126.24,   3088.64,   3088.6 ,   3082.12,   3080.85,\n",
       "         3057.35,   3054.35,   3010.68,   2994.04,   2969.19,   2931.84,\n",
       "         2889.41,   2867.64,   2829.  ,   2813.62,   2801.78,   2787.14,\n",
       "         2779.84,   2749.28,   2746.3 ,   2744.84,   2726.08,   2724.52,\n",
       "         2721.33,   2691.69,   2676.74,   2666.  ,   2661.46,   2654.04,\n",
       "         2651.95,   2638.53,   2632.51,   2621.44,   2610.  ,   2607.98,\n",
       "         2598.28,   2595.6 ,   2592.  ,   2590.84,   2583.09,   2570.4 ,\n",
       "         2566.  ,   2547.  ,   2539.13,   2494.65,   2487.09,   2485.  ,\n",
       "         2483.58,   2480.6 ,   2480.  ,   2478.  ,   2462.4 ,   2443.7 ,\n",
       "         2435.  ,   2433.83,   2429.15,   2421.62,   2399.59,   2395.68,\n",
       "         2392.38,   2379.87,   2375.54,   2374.04,   2356.  ,   2354.91,\n",
       "         2336.  ,   2329.  ,   2322.46,   2317.95,   2316.  ,   2314.21,\n",
       "         2297.56,   2288.  ,   2287.  ,   2282.  ,   2278.  ,   2276.  ,\n",
       "         2275.  ,   2271.38,   2249.68,   2242.94,   2192.  ,   2189.  ,\n",
       "         2167.99,   2166.52,   2164.  ,   2157.41,   2155.99,   2152.  ,\n",
       "         2133.  ,   2129.54,   2121.  ,   2115.  ,   2109.  ,   2094.  ,\n",
       "         2089.98,   2088.83,   2087.  ,   2078.  ,   2076.89,   2075.  ,\n",
       "         2074.04,   2071.39,   2059.88,   2045.93,   2028.  ,   2027.52,\n",
       "         2026.  ,   2016.  ,   2014.46,   2011.  ,   2007.  ,   2003.  ,\n",
       "         2001.99,   2000.  ,   1999.5 ,   1997.  ,   1985.  ,   1983.15,\n",
       "         1980.53,   1979.  ,   1976.  ,   1975.07,   1975.  ,   1967.81,\n",
       "         1966.08,   1963.  ,   1955.  ,   1952.  ,   1934.  ,   1929.37,\n",
       "         1928.  ,   1926.4 ,   1921.  ,   1914.59,   1914.38,   1905.48,\n",
       "         1901.  ,   1896.75,   1896.  ,   1882.56,   1872.  ,   1871.  ,\n",
       "         1870.73,   1861.37,   1854.  ,   1853.  ,   1849.  ,   1840.89,\n",
       "         1838.  ,   1835.52,   1833.  ,   1832.  ,   1831.49,   1829.86,\n",
       "         1828.02,   1825.  ,   1824.  ,   1820.  ,   1815.  ,   1814.  ,\n",
       "         1809.34,   1807.  ,   1804.  ,   1802.51,   1790.  ,   1785.62,\n",
       "         1768.59,   1765.81,   1765.  ,   1756.75,   1750.18,   1746.  ,\n",
       "         1741.02,   1736.  ,   1735.66,   1729.  ,   1728.88,   1724.45,\n",
       "         1715.81,   1714.  ,   1706.73,   1703.51,   1703.28,   1691.  ,\n",
       "         1686.54,   1684.19,   1683.37,   1683.  ,   1671.37,   1670.09,\n",
       "         1668.16,   1667.72,   1661.  ,   1653.92,   1653.22,   1652.9 ,\n",
       "         1652.49,   1649.11,   1646.  ,   1644.36,   1643.  ,   1642.54,\n",
       "         1639.3 ,   1635.02,   1632.96,   1630.13,   1623.7 ,   1608.22,\n",
       "         1605.  ,   1603.23,   1601.  ,   1593.03,   1590.  ,   1587.  ,\n",
       "         1582.  ,   1579.98,   1569.  ,   1562.  ,   1560.  ,   1558.4 ,\n",
       "         1555.97,   1552.44,   1551.51,   1537.19,   1524.72,   1521.94,\n",
       "         1520.97,   1511.  ,   1498.32,   1492.78,   1477.92,   1473.  ,\n",
       "         1471.  ,   1464.  ,   1462.27,   1457.73,   1443.56,   1432.9 ,\n",
       "         1432.  ,   1431.1 ,   1428.  ,   1418.  ,   1417.  ,   1416.  ,\n",
       "         1415.47,   1412.  ,   1411.  ,   1407.  ,   1405.  ,   1403.  ,\n",
       "         1400.88,   1391.  ,   1389.  ,   1379.  ,   1363.48,   1361.77,\n",
       "         1359.  ,   1353.87,   1352.  ,   1348.56,   1346.76,   1346.  ,\n",
       "         1345.  ,   1344.  ,   1337.  ,   1326.25,   1325.15,   1319.52,\n",
       "         1316.84])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supercom_df['Rmax [TFlop/s]'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we can see that the representation is consistently float, even for those with no decimal values. The values are also not set to a default value of 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Rpeak [TFlop/s]` variable\n",
    "As `Rpeak` uses the same unit as `Rmax`, the process for checking and cleaning the data is similar: (1) the data type should be a floating point, (2) there should be no NaN/null values, and (3) it should not be set to the default value of 0.\n",
    "\n",
    "As `Rpeak` also uses the object data type, we first need to convert it to a float using the [`astype`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html) function. The [`replace`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html) function is also used again to remove commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "supercom_df['Rpeak [TFlop/s]'] = supercom_df['Rpeak [TFlop/s]'].replace(',','', regex=True)\n",
    "supercom_df['Rpeak [TFlop/s]'] = supercom_df['Rpeak [TFlop/s]'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in the previous variables, after using the [`astype`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html) function, we can use the [`info`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html) function to see if the casting is successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 37 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Rank                             500 non-null    int64  \n",
      " 1   Previous Rank                    456 non-null    float64\n",
      " 2   First Appearance                 500 non-null    int64  \n",
      " 3   First Rank                       500 non-null    int64  \n",
      " 4   Name                             315 non-null    object \n",
      " 5   Computer                         500 non-null    object \n",
      " 6   Site                             500 non-null    object \n",
      " 7   Manufacturer                     500 non-null    object \n",
      " 8   Country                          500 non-null    object \n",
      " 9   Year                             500 non-null    int64  \n",
      " 10  Segment                          500 non-null    object \n",
      " 11  Total Cores                      500 non-null    int32  \n",
      " 12  Accelerator/Co-Processor Cores   149 non-null    object \n",
      " 13  Rmax [TFlop/s]                   500 non-null    float64\n",
      " 14  Rpeak [TFlop/s]                  500 non-null    float64\n",
      " 15  Nmax                             495 non-null    object \n",
      " 16  Nhalf                            12 non-null     object \n",
      " 17  HPCG [TFlop/s]                   73 non-null     object \n",
      " 18  Power (kW)                       189 non-null    object \n",
      " 19  Power Source                     189 non-null    object \n",
      " 20  Power Efficiency [GFlops/Watts]  189 non-null    float64\n",
      " 21  Architecture                     500 non-null    object \n",
      " 22  Processor                        500 non-null    object \n",
      " 23  Processor Technology             500 non-null    object \n",
      " 24  Processor Speed (MHz)            500 non-null    object \n",
      " 25  Operating System                 500 non-null    object \n",
      " 26  OS Family                        500 non-null    object \n",
      " 27  Accelerator/Co-Processor         500 non-null    object \n",
      " 28  Cores per Socket                 500 non-null    int64  \n",
      " 29  Processor Generation             500 non-null    object \n",
      " 30  System Model                     500 non-null    object \n",
      " 31  System Family                    500 non-null    object \n",
      " 32  Interconnect Family              500 non-null    object \n",
      " 33  Interconnect                     500 non-null    object \n",
      " 34  Continent                        500 non-null    object \n",
      " 35  Site ID                          500 non-null    object \n",
      " 36  System ID                        500 non-null    int64  \n",
      "dtypes: float64(4), int32(1), int64(6), object(26)\n",
      "memory usage: 142.7+ KB\n"
     ]
    }
   ],
   "source": [
    "supercom_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, we need to check if there are observations with the NaN/null value for this column using the [`isnull`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.isnull.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supercom_df['Rpeak [TFlop/s]'].isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are no NaN/null value for the `Rpeak [TFlop/s]` column, we can now proceed to check for unique values using the [`unique`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.unique.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([537212.  , 200794.88, 125712.  , 125435.9 ,  79215.  , 100678.66,\n",
       "        70980.  ,  51720.76,  38745.91,  55423.56,  29354.  ,  27154.3 ,\n",
       "        41461.15,  32576.63,  26873.86,  25159.68,  23047.2 ,  25025.81,\n",
       "        19464.2 ,  27880.65,  25705.9 ,  24913.46,  18621.14,  23396.35,\n",
       "        18309.22,  11209.11,  15142.2 ,  15208.23,  11032.03,  10321.92,\n",
       "        12127.07,  13977.6 ,  10510.66,  10469.38,  12902.4 ,   9492.16,\n",
       "         8128.51,  12039.37,  11661.31,   8789.76,   7785.68,  10296.12,\n",
       "         7455.92,   9891.07,   8439.62,   7107.15,   8911.26,   9220.61,\n",
       "         9125.22,   9793.54,   7235.17,   8316.52,   7060.68,   7630.85,\n",
       "         6712.32,   6981.48,   7519.3 ,   7257.6 ,   5332.32,   6193.15,\n",
       "         5267.14,   6912.  ,   7345.56,   8848.49,   6134.17,   7136.87,\n",
       "         6618.93,   6628.15,   5783.81,   4718.59,   6635.52,   5369.86,\n",
       "         4249.33,   6563.84,   4006.2 ,   5365.09,   6023.99,   5419.01,\n",
       "         5750.78,   6253.06,   6131.84,   5879.81,   6844.8 ,   5120.  ,\n",
       "         6412.03,   5834.4 ,   4570.56,   4896.51,   3791.58,   4592.64,\n",
       "         4777.57,   4605.  ,   5371.78,   5014.73,   3481.06,   4352.41,\n",
       "         4881.25,   5610.48,   6080.  ,   4608.  ,   4971.11,   4884.48,\n",
       "         5483.52,   4867.2 ,   3962.88,   5888.  ,   4335.21,   5760.  ,\n",
       "         4709.38,   6327.55,   3670.43,   3578.27,   3019.16,   4190.21,\n",
       "         5440.  ,   5376.  ,   5312.  ,   5354.88,   3761.66,   3894.91,\n",
       "         5248.  ,   4085.76,   4219.09,   5184.  ,   5529.6 ,   4710.4 ,\n",
       "         4829.34,   3207.86,   4354.56,   4895.54,   4359.98,   3798.6 ,\n",
       "         4992.  ,   5145.6 ,   2808.69,   4701.  ,   3847.22,   4229.85,\n",
       "         3388.03,   3570.28,   4915.2 ,   3682.36,   4112.64,   3299.33,\n",
       "         4680.  ,   4946.79,   4800.  ,   2601.98,   4004.25,   4736.  ,\n",
       "         4239.36,   4704.  ,   4180.48,   2895.36,   4640.  ,   4684.8 ,\n",
       "         3686.4 ,   4121.6 ,   2812.8 ,   4368.  ,   4480.  ,   3581.76,\n",
       "         4412.1 ,   4003.84,   2867.41,   4890.  ,   7494.78,   3923.71,\n",
       "         3905.28,   2688.  ,   3041.28,   4320.  ,   4515.84,   4816.  ,\n",
       "         2534.4 ,   4160.  ,   4423.68,   2585.09,   4300.8 ,   8973.31,\n",
       "         4406.89,   7112.7 ,   4056.  ,   3903.43,   4652.03,   3434.09,\n",
       "         4000.  ,   3072.  ,   2846.4 ,   3843.38,   4225.2 ,   2984.45,\n",
       "         5245.78,   4018.18,   3074.53,   3862.25,   3936.  ,   4648.18,\n",
       "         3840.  ,   4080.38,  44982.27,   3744.  ,   8160.77,   3693.54,\n",
       "         2985.98,   3053.57,   2359.3 ,   4104.32,  39936.  ,   3776.  ,\n",
       "         3052.34,   4096.51,   6594.56,   4010.48,   2800.87,   2491.37,\n",
       "         3603.46,   3960.32,   3921.41,   3905.13,   2409.6 ,   4618.  ,\n",
       "         3974.4 ,   3981.31,   3520.51,   3660.8 ,   4292.35,   3179.52,\n",
       "         3843.84,   2193.01,   3816.96,   3612.67,  15162.37,   2586.01,\n",
       "         2801.41,   3520.  ,   4080.05,   3432.  ,   2727.03,   2687.39,\n",
       "         3698.69,   6123.52,   2298.24,   7436.8 ,   3456.  ,   4329.73,\n",
       "         4981.76,   3353.18,   3669.12,   4140.03,   3644.93,   2674.1 ,\n",
       "         3021.6 ,   2923.78,   2438.14,   3696.  ,   3072.77,   2861.57,\n",
       "         7312.9 ,   2672.64,   2709.5 ,   2568.19,  81410.56,   7206.91,\n",
       "         2799.36,   3978.24,   3440.64,   2816.  ,   3149.6 ,   2737.15,\n",
       "         2304.  ,   2703.36,   2488.32,   2695.68,   3446.78,   3290.11,\n",
       "         2348.64,   2674.94,   3207.17,   2472.96,   2467.7 ,   3137.87,\n",
       "         2759.68,   2119.68,   2649.29,   3788.8 ,   3766.37,   2550.53,\n",
       "         2036.74,   3715.89,   2637.71,   1904.64,   3008.  ,   2323.28,\n",
       "         3333.12,   2580.48,   2573.38,   3225.6 ,   1931.63,   2399.74,\n",
       "         2944.  ,   6535.68,   3238.4 ,   2987.52,   2509.04,   2880.  ,\n",
       "         3182.59,   1792.63,   2444.71,   2412.54,   2752.  ,   3931.2 ,\n",
       "         3000.  ,   1739.78,   2011.64,   2316.04,   2153.54,   5772.8 ,\n",
       "         2624.  ,   1677.72,   1920.  ,   2413.82,   2914.56,   1999.87,\n",
       "         1530.55,   3907.58,   2890.24,   2226.56,   5793.79,   5740.8 ,\n",
       "         3553.18,   2329.6 ,   3068.93,   2560.  ,   4917.66,   2953.6 ,\n",
       "         2459.  ,   2903.04,   1676.51,   1836.17,   1667.17,   2073.6 ,\n",
       "         2332.  ,   2780.47,   2457.6 ,   3489.02,   2770.94,   2863.41,\n",
       "         2027.52,   2088.96,   2400.  ,   2393.6 ])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supercom_df['Rpeak [TFlop/s]'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the values of `Rpeak [TFlop/s]` column are complete (i.e. there's no NaN/null values), its data type is floating point, and the values are not the default 0 value, we can proceed to the next variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Rank` variable\n",
    "As this dataset is a ranking of the Top 500 supercomputers, we are expecting four things from the `Rank` variable: (1) its data type is an integer, (2) its values range from 1 to 500, (3) there are no duplicate values for the ranking, and (4) there are no NaN/null values.\n",
    "\n",
    "Using the [`info`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html) function, we can check if the `Rank` variable is stored as an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 37 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Rank                             500 non-null    int64  \n",
      " 1   Previous Rank                    456 non-null    float64\n",
      " 2   First Appearance                 500 non-null    int64  \n",
      " 3   First Rank                       500 non-null    int64  \n",
      " 4   Name                             315 non-null    object \n",
      " 5   Computer                         500 non-null    object \n",
      " 6   Site                             500 non-null    object \n",
      " 7   Manufacturer                     500 non-null    object \n",
      " 8   Country                          500 non-null    object \n",
      " 9   Year                             500 non-null    int64  \n",
      " 10  Segment                          500 non-null    object \n",
      " 11  Total Cores                      500 non-null    int32  \n",
      " 12  Accelerator/Co-Processor Cores   149 non-null    object \n",
      " 13  Rmax [TFlop/s]                   500 non-null    float64\n",
      " 14  Rpeak [TFlop/s]                  500 non-null    float64\n",
      " 15  Nmax                             495 non-null    object \n",
      " 16  Nhalf                            12 non-null     object \n",
      " 17  HPCG [TFlop/s]                   73 non-null     object \n",
      " 18  Power (kW)                       189 non-null    object \n",
      " 19  Power Source                     189 non-null    object \n",
      " 20  Power Efficiency [GFlops/Watts]  189 non-null    float64\n",
      " 21  Architecture                     500 non-null    object \n",
      " 22  Processor                        500 non-null    object \n",
      " 23  Processor Technology             500 non-null    object \n",
      " 24  Processor Speed (MHz)            500 non-null    object \n",
      " 25  Operating System                 500 non-null    object \n",
      " 26  OS Family                        500 non-null    object \n",
      " 27  Accelerator/Co-Processor         500 non-null    object \n",
      " 28  Cores per Socket                 500 non-null    int64  \n",
      " 29  Processor Generation             500 non-null    object \n",
      " 30  System Model                     500 non-null    object \n",
      " 31  System Family                    500 non-null    object \n",
      " 32  Interconnect Family              500 non-null    object \n",
      " 33  Interconnect                     500 non-null    object \n",
      " 34  Continent                        500 non-null    object \n",
      " 35  Site ID                          500 non-null    object \n",
      " 36  System ID                        500 non-null    int64  \n",
      "dtypes: float64(4), int32(1), int64(6), object(26)\n",
      "memory usage: 142.7+ KB\n"
     ]
    }
   ],
   "source": [
    "supercom_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the `Rank` variable is already an integer, we will now check if its values are from 1 to 500 using the [`unique`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.unique.html) function. It should be noted that all numbers from 1 to 500 should be returned by this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
       "       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "       170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
       "       183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "       196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
       "       209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
       "       222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
       "       235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
       "       248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n",
       "       261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273,\n",
       "       274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286,\n",
       "       287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299,\n",
       "       300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n",
       "       313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
       "       326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
       "       339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
       "       352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
       "       365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
       "       378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n",
       "       391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n",
       "       404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n",
       "       417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429,\n",
       "       430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n",
       "       443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n",
       "       456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468,\n",
       "       469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
       "       482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
       "       495, 496, 497, 498, 499, 500], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supercom_df['Rank'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it seems that all values are present, the [`value_counts`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) function is used to check for any duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500    1\n",
       "171    1\n",
       "158    1\n",
       "159    1\n",
       "160    1\n",
       "      ..\n",
       "339    1\n",
       "340    1\n",
       "341    1\n",
       "342    1\n",
       "1      1\n",
       "Name: Rank, Length: 500, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supercom_df['Rank'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we need to check if there are NaN/null values for the `Rank` variable. Like in the previous variables, we would be using the [`isnull`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html) and [`any`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.any.html) functions for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supercom_df['Rank'].isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the `Rank` column is ready for analysis, we can now proceed to the next variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Segment` Variable\n",
    "Since the `Segment` variable talks about the purpose of the supercomputer, it is stored as an object. As such, we need to check the values of this variable for any typographical errors when it was encoded. We can use the [`unique`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html) function to list all unique values for this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Research', 'Vendor', 'Industry', 'Academic', 'Government',\n",
       "       'Others'], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supercom_df['Segment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the unique values for the `Segment` variable are all represented correctly (i.e. no typographical errors, no duplicate representations). Thus, we do not need to do anything more to the `Segment` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Country` Variable\n",
    "As the `Country` variable indicates which country a specific supercomputer, we expect its value to be an object type. However, we still need to check if there are missing data or multiple representations (e.g. 'Singapore' and 'singapore' is the same country and should be represented as the same) of the data. The [`unique`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html) function is called again to list all unique values for this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Japan', 'United States', 'China', 'Germany', 'Italy',\n",
       "       'Saudi Arabia', 'Switzerland', 'France', 'South Korea',\n",
       "       'Australia', 'Taiwan', 'United Arab Emirates', 'United Kingdom',\n",
       "       'Russia', 'Spain', 'Finland', 'Norway', 'India', 'Brazil',\n",
       "       'Canada', 'Poland', 'Morocco', 'Sweden', 'Austria', 'Netherlands',\n",
       "       'Ireland', 'Singapore', 'Hong Kong', 'Czechia'], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supercom_df['Country'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the output of the [`unique`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html) function, we can see that the values of the `Country` column are all within the set of accepted values and that there are no NaN/null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Processor Technology` Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Processor Technology` variable tells what is the logic circuitry used by the supercomputer, as such we can use the [`unique`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html) function to check for the different values in this column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fujitsu ARM', 'Power', 'ShenWei', 'AMD Zen-2 (Rome)',\n",
       "       'Intel IvyBridge', 'Intel Cascade lake', 'Intel Haswell',\n",
       "       'Intel Xeon Phi', 'Intel Skylake', 'Intel Broadwell',\n",
       "       'NEC Vector Engine', 'X86_64', 'Sparc', 'Intel Nehalem',\n",
       "       'Intel SandyBridge', 'ThunderX2', 'AMD Zen (Naples)', 'PowerPC'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supercom_df['Processor Technology'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the output of the [`unique`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html) function, the values of the `Processor Technology` column are all valid, free of multiple representations of the same value, and has no NaN/null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the given dataset, there is a substantial amount of raw data to process and analyze. Before performing any statistical analysis, it is good practice to do exploratory data analysis to observe patterns and detect any outliers in the dataset. With this, we can properly identify particular relationships between specific variables.\n",
    "\n",
    "**Three exploratory data analysis questions have been identified and formulated:**\n",
    "1. Is there a correlation between the current `Rank` of a supercomputer and their `Total Cores`?\n",
    "2. Which `Country` has the most number of supercomputers?\n",
    "3. How varied are the `Rmax [TFlop/s]` values of the supercomputers?\n",
    "\n",
    "To answer these questions, we used numerical summaries which include the measures of central tendency, the measures of dispersion, and correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there a correlation between the current `Rank` of a supercomputer and their `Total Cores`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Rank` variable is defined as the current position of a supercomputer in the Top 500, while the `Total Cores` variable defines the total number of cores that a supercomputer has in its system. In this part, we would be investigating for any potential relationships between the `Total Cores` and the `Rank` variable using correlation. \n",
    "\n",
    "Before we start checking for the correlation of the two variables, let us first get familiar with their basic statistical details (i.e. percentiles, mean, standard deviation, minimum value, maximum value, and the number of observations) using the [`describe`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    500.000000\n",
       "mean     250.500000\n",
       "std      144.481833\n",
       "min        1.000000\n",
       "25%      125.750000\n",
       "50%      250.500000\n",
       "75%      375.250000\n",
       "max      500.000000\n",
       "Name: Rank, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supercom_df['Rank'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.000000e+02\n",
       "mean     1.449323e+05\n",
       "std      6.461345e+05\n",
       "min      1.664000e+03\n",
       "25%      4.641000e+04\n",
       "50%      5.760000e+04\n",
       "75%      8.563200e+04\n",
       "max      1.064960e+07\n",
       "Name: Total Cores, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supercom_df['Total Cores'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better visualize the values and the relationship between the two variables `Rank` and `Total Cores`, we can use the [`plot`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html) function to display a scatterplot with the `Total Cores` as its y-axis and the `Rank` as its x-axis. \n",
    "\n",
    "In this scenario, a scatterplot is used since the scenario aims to determine if there is a monotonic relationship between the two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Scatterplot of the Rank vs Total Cores of a Supercomputer')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(supercom_df['Rank'], supercom_df['Total Cores'], 'r+')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Total Cores')\n",
    "plt.title('Scatterplot of the Rank vs Total Cores of a Supercomputer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scatterplot produced above, it is apparent that there is a relationship between the two variables. More specifically, a strong, linear, and negative relationship can be observed between the `Rank` and the `Total Cores` of a supercomputer.\n",
    "\n",
    "Furthermore, we can also use the [`spearmanr`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html) function to compute for the Spearman Correlation value of these variables. This can be used to discover the strength of the a link between two columns from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman's Correlation coefficient = -0.57\n",
      "\n",
      "Samples are correlated p = 0.00\n"
     ]
    }
   ],
   "source": [
    "coef, p = stats.spearmanr(supercom_df['Rank'], supercom_df['Total Cores'])\n",
    "print('Spearman\\'s Correlation coefficient = %.2f\\n' % coef)\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Samples are uncorrelated p = %.2f' % p)\n",
    "else:\n",
    "\tprint('Samples are correlated p = %.2f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From both the scatterplot and the Spearman correlation coefficient, we can come to a definitive conclusion that there is a monotonic, specifically a negative, association between the two variables. Simply put, as the `Rank` of a supercomputer increases, the number of `Total Cores` it has decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which `Segment` has the most number of supercomputers?\n",
    "The `Segment` variable refers to the current sector that uses the supercomputer. For this part, we would be checking which segment appears most frequently in the dataset; this value is also known as the mode, a measure of central tendency. \n",
    "\n",
    "To start, the [`groupby`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) function is used to group the observations according to their country. The [`agg`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html) function is called to aggregate the count, which would then be sorted using the [`sort_values`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            count\n",
      "Segment          \n",
      "Industry      132\n",
      "Research       86\n",
      "Academic       62\n",
      "Government     24\n",
      "Vendor          8\n",
      "Others          3\n"
     ]
    }
   ],
   "source": [
    "grouped_df = supercom_df.groupby(\"Segment\")\n",
    "grouped_df = grouped_df[\"Name\"].agg(['count']).sort_values(['count'], ascending=False)\n",
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better visualize the results of this table, we can use the [`plot`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html) function to display a bar graph using the given data. \n",
    "\n",
    "A bar graph is most suitable to show which country appears most frequently as bar graphs allows one to visually distinguish the differences between any two countries. This would allow us to quickly observe which country has the most supercomputers, especially in comparison to other countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'country_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-b4810c61bf6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcountry_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"bar\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of Supercomputers per Segment\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Segment Name\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of Supercomputers\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'country_df' is not defined"
     ]
    }
   ],
   "source": [
    "country_df['count'].plot(kind=\"bar\")\n",
    "\n",
    "plt.title(\"Number of Supercomputers per Segment\")\n",
    "plt.xlabel(\"Segment Name\")\n",
    "plt.ylabel(\"Number of Supercomputers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From both the list and the graph, we can see that the mode or the segment that appears most frequently in the list is Industry. With this, we can conclude that the majority of high-performance supercomputers in the world are currently being used by the industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How varied are the `Rmax [TFlop/s]` values of the supercomputers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Rmax [TFlop/s]` variable refers to the maximum LINPACK performance achieved by the supercomputer. In this part, we will check the dispersion of values in the Rmax variable using the measures of dispersion, particularly range and interquartile range.  \n",
    "\n",
    "Before performing any analysis, the [`describe`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html) function is called for us to see some of the summarized statistics about the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmax_df = supercom_df['Rmax [TFlop/s]']\n",
    "rmax_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the range of the values is found by obtaining the minimum and maximum values in the dataset. The range is a good indicator of the dispersion of values in small datasets, although the value may be misleading if there are any outliers.\n",
    "\n",
    "We can compute the **range** using the formula:\n",
    "\n",
    "$$range = max - min$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmax_max = max(rmax_df)\n",
    "rmax_min = min(rmax_df)\n",
    "rmax_range = rmax_max - rmax_min\n",
    "print('Range: {:.2f}'.format(rmax_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The range of the Rmax values of the supercomputers is 440693.16 TFlop/s, which signifies high variability in the given data. This may be possible due to any outliers in the data which affected the whole range. Knowing this, our next step is to identify the interquartile range (IQR); this measure can be used as it is based on values from the middle half of the distribution, effectively avoiding any outliers. \n",
    "\n",
    "We can compute the **interquartile range** using the formula:\n",
    "\n",
    "$$IQR = Q3 - Q1$$\n",
    "\n",
    "From using the [`describe`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html) function earlier, we were able to get the first quartile (25%) and third quartile (75%) of the `Rmax [TFlop/s]` variable. Aside from this, we can also use the [`quantile`](https://numpy.org/doc/stable/reference/generated/numpy.quantile.html) function to get these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3 = np.quantile(rmax_df, 0.75)\n",
    "Q1 = np.quantile(rmax_df, 0.25)\n",
    "IQR = Q3 - Q1\n",
    "print(\"IQR: %.2f\" % (IQR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the IQR (1073.02 TFlop/s) to the range (440693.16 TFlop/s), there is a noticable difference between the two, which means that we can confirm the existence of an unusually high outlier in the data. \n",
    "\n",
    "For clearer analysis, the data will be visualized as a box plot; the box plot will be used to quickly see the dispersion of the data and also highlight any potential outliers in the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmax_df.plot.box(grid='True', title='Box plot of Rmax [TFlop/s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The earlier conclusions are evident in this boxplot; several outliers in the data should be adequately taken into account when forming insights about the dataset.\n",
    "\n",
    "Returning to the question at hand, the range should not be used as a measure of dispersion in this specific case due to outliers. Instead, a much more accurate representation of the data's variance is the quartiles and the IQR. Therefore, from the values of the Q1 and Q3 obtained earlier, we are able to properly conclude that the middle 50% of our data is spread from 1649.110000 TFlop/s to 2722.127500 TFlop/s with an IQR of 1073.02 TFlop/s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Questions\n",
    "Now that we have sufficiently explored the dataset and found patterns and relationships between variables, the research questions can now be formulated. Research questions define the scope of a project, which would effectively guide us in analyzing the dataset. \n",
    "\n",
    "As seen from the EDA done in the previous section, supercomputers are widely used in professional sectors. This assumption raises several interesting questions, particularly concerning the `Segment` variable of the supercomputer. These questions would be the core focus of the research questions, as we aim to properly investigate whether or not the performance and specifications of a supercomputer rely on its purpose.\n",
    "\n",
    "#### Is there a significant difference between the means of the `Rmax [TFlop/s]` of the professional sectors?\n",
    "In high-performance computing, Rmax and Rpeak are scores used to rank supercomputers based on their performance using the LINPACK Benchmark. A system's Rmax score describes its maximal achieved performance; the Rpeak score describes its theoretical peak performance. /* TODO: explain kung bakit rmax pinili hindi rpeak: Rpeak is just a theoretical value, while yung rmax is ung mismong lumabas na value nung nagexperiment sila (ginamit yung supercomputer for LINPACK) */ This research question aims to determine /* parang kapag nalaman mo kung may difference yung average Rmax between diff. segments, pwede siyang makatulong na maging basis sa future supercomputers. like if magiging sagot is mayroong significant difference pwede siyang mag-cause ng **future studies** na magsasabi if kailangan mong malaman yung purpose ng supercomputer before siya gawin since may expectation sa supercomputer mo basae sa purpose niya. pero, if wala namang significant different, pwedeng magkaroon ng **future studies** na kung saan hahanapin yung \"pagkakasunduan\" na expectation sa Rmax ng mga segments-> general purpose supercomputer. */\n",
    "\n",
    "/* importance and significance: all in all, pwede siya makatulong future supercomputers na para maging at least guidelines sa mga minimum na ineexpect sa kanila. */\n",
    "\n",
    "Professional sectors such as academic, government, industry and research were chosen because these four sectors are the main driving factors of the development of the nation. /* TODO: define what driving factors of development mean + kapag nadefine mo na, connect mo yung magiging dulot ng better supercomputers sa development ng world */\n",
    "\n",
    "#### Is there a significant relationship between a supercomputer's `Processor Technology` and the `Segment` of the industry it belongs in? \n",
    "/* TODO: purpose/importance ng processor technology sa supercomputer. if makikita na mayroong significant relationship between the variables, pwede siya magkaroon ng supporting study na inaalam kung bakit nga ba nakakaapekto ung segment/purpose sa choice ng processor technology. like, pwedeng alamin na ano yung hinahanap ng isang industry sa processor technology na naglelead na ito yung pipiliin if ito yung purpose.*/\n",
    "\n",
    "/* importance and significance: smth like supercomputers are used by the diff. sectors para mapadali yung development ng buhay ng karamihan at makagawa ng changes so understanding paano nakakaaffect yung diff. factors sa paggawa ng supercomputer ay pwedeng maglead sa paggawa ng better supercomputers to handle diff. needs */"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Inference\n",
    "In order for us to find the answer to our research questions, we have to undergo the process of statistical inference. In this notebook, statistical inference for means and for categorical data would be both utilized, especifically ANOVA and Two-way Table that uses Chi Square Statistic.\n",
    "\n",
    "### `Rmax` of Supercomputers across Professional `Segments` of the Industry\n",
    "\n",
    "#### Step 1: Data Pre-processing\n",
    "Because the `Rmax [TFlop/s]` column is a continuous numerical data, we need to check if there is an outlier in the data. The interquartile range (IQR) is used to remove the outliers by setting a limit around the dataset's first quartile (*Q1*) and third quartile (*Q3*). This means that the range of the `Rmax [TFlop/s]` would be 1.5 times times the IQR lower than the Q1 to the 1.5 times IQR higher than Q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmax_df = supercom_df\n",
    "\n",
    "Q3 = np.quantile(rmax_df['Rmax [TFlop/s]'], 0.75)\n",
    "Q1 = np.quantile(rmax_df['Rmax [TFlop/s]'], 0.25)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_range = Q1 - 1.5 * IQR\n",
    "upper_range = Q3 + 1.5 * IQR\n",
    "outlier_free_list = [x for x in rmax_df['Rmax [TFlop/s]'] if ((x > lower_range) & (x < upper_range))]\n",
    "filtered_data = rmax_df.loc[rmax_df['Rmax [TFlop/s]'].isin(outlier_free_list)]\n",
    "\n",
    "data = filtered_data\n",
    "grouped_df = data\n",
    "print(grouped_df['Rmax [TFlop/s]'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 500 values, the number of `Rmax [TFlop/s]` values went down to 435. This means that there are 65 observations that are outliers. In this scenario, it is better to drop the outliers as we want to find out about if there is a significant difference between the `Rmax [TFlop/s]` value of the supercomputers of the `Segments`. As such, having outliers might greatly affect the mean of a group, which would result to the value of its mean not representing the whole of its sample group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Computing the means of each `Segment`\n",
    "Since the given data set gives the `Rmax [TFlop/s]` of each supercomputer, we first have to group the supercomputers based on the value of their `Segment` variable. This can be done with the use of the [`groupby`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) function. Additionally, using the [`agg`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html) function, we can compute for the mean and standard deviation of each group, while creating columns for the two and the number of observations inside each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = grouped_df.groupby(\"Segment\")\n",
    "grouped_df = grouped_df['Rmax [TFlop/s]'].agg(['count','mean', 'std']).reset_index()\n",
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of the aforementioned two functions resulted to a data frame with six observations. Each of these observations represent one group from the `Segment` variable. However, since our research question focuses only on the professional sectors of the industry (i.e. academic, government, industry and research), we would need to drop the other two segments using the [`drop`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = grouped_df.drop([grouped_df.index[5], grouped_df.index[3]]).reset_index()\n",
    "grouped_df = grouped_df.drop(\"index\", axis=1)\n",
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Checking if our data is normally distributed\n",
    "We can say that each of our groups are nearly normally distributed because they all pass the Central Limit Theorem. The Central Limit Theorem states that when we have a sufficiently large sample of independent observations, we can assume that the sampling distribution will be nearly distributed. The Central Limit Theorem holds true for sample sizes that are over 30.\n",
    "\n",
    "Since each of our groups have a sample size of at least 30 samples which are independent of each other, we can say that the Central Limit Theorem holds for our samples. Thus, we can say that our sampling distribution is nearly normally distributed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Deciding which Statistical Inference for Means method\n",
    "As we aim to see if there is a significant difference between the mean of more than two groups, the correct method to use is Analysis of Variance (ANOVA). However, ANOVA testing will not identify which `Segment` group differs from the other groups or how many groups has significant differences with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Calculating for the Overall Mean\n",
    "Since we are going to use ANOVA, there is also a need to compute for the overall mean of the groups. The `overall mean` refers to the total mean of each sample. In the computation of the `overall mean`, we add each of the samples and divide the sum with the total number of samples. For this research question, we will add all of the 477 samples (disregarding their groups, first), and divide the sum by 477. \n",
    "\n",
    "However, the mean of the group means is not always equal to the `overall mean`. Because of this, we have to refer to the original data set and remove the samples that are out of the scope of this research question. Thus, we have to remove the samples that are from the `Segment` Vendor and Others, as we are only calculating for the mean of the professional sectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = data.copy()\n",
    "\n",
    "index_names = new_df[new_df['Segment'] == 'Others'].index\n",
    "index_names2 = new_df[new_df['Segment'] == 'Vendor'].index\n",
    "\n",
    "new_df.drop(index_names, inplace=True)\n",
    "new_df.drop(index_names2, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we now have the data set that is relevant to our research question, we can now calculate the `overall mean` using the [`mean`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_mean = new_df['Rmax [TFlop/s]'].mean()\n",
    "print('\\nOverall mean: ', overall_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Setting the Hypothesis\n",
    "To be able to know if there is a significant difference between the means of the `Rmax [TFlop/s]` of the professional sectors, we have to set up the null and alternative hypotheses. For this research question, the null hypothesis states that there is no significant difference between the means of the `Rmax [TFlop/s]` of the professional sector. \n",
    "\n",
    "$H_{0}$ (null hypothesis): $_{A}$ = $_{G}$ = $_{I}$ = $_{R}$\n",
    "\n",
    "On the other hand, the alternative hypothesis states that there is at least one mean that varies from the rest of the group.\n",
    "\n",
    "$H_{A}$ (alternative hypothesis): At least one of the means varies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Setting the Significance level\n",
    "For this research question, we will be setting the significance level () to 0.05. This means that if the p-value that we would be getting from the F-value is less than or equal 0.05, we will be rejecting the null hypothesis. On the other hand, if the p-value is greater than 0.05, we will be accepting the null hypothesis.\n",
    "\n",
    " = 0.05\n",
    "\n",
    "This also implies that there is a 5% risk of rejecting the null hypothesis when it should have been accepted (i.e. Type I Error)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8: Calculating the Confidence Interval and Margin of Error\n",
    "For this research, the confidence interval for each of the group's mean is computed in order to set the range that the groups' `Rmax [TFlop/s]` mean would fall in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_star_95 = stats.norm.ppf(0.975)\n",
    "margin_of_error = []\n",
    "min_interval = []\n",
    "max_interval = []\n",
    "\n",
    "for x in range (4):\n",
    "    temp = grouped_df.iloc[x]\n",
    "    margin = z_star_95 * temp[\"std\"]/np.sqrt(temp[\"count\"])\n",
    "    margin_of_error.append (margin)\n",
    "    min_interval.append(temp[\"mean\"] - margin)\n",
    "    max_interval.append(temp[\"mean\"] + margin)\n",
    "    \n",
    "    \n",
    "grouped_df[\"margin of error\"] = margin_of_error\n",
    "grouped_df[\"min confidence interval\"] = min_interval\n",
    "grouped_df[\"max confidence interval\"] = max_interval\n",
    "\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the margin of error and the confidence interval of the all samples are also computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_std = new_df['Rmax [TFlop/s]'].std()\n",
    "overall_margin = z_star_95 * overall_std/np.sqrt(len(new_df))\n",
    "min_overall = overall_mean - overall_margin\n",
    "max_overall = overall_mean + overall_margin\n",
    "\n",
    "print('Overall sample:')\n",
    "print('Margin of error: ', overall_margin)\n",
    "print('Confidence interval: (', min_overall, \",\", max_overall, ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9: Calculating the Sum of Squares\n",
    "Before calculating the sum of squares, we first need to set the value of *k* and *n*. Since *k* refers to the total number of groups, the value of *k* would be equal to four (i.e. academic, research, industry, government). On the other hand, *n* refers to the total sample size across the group. This means that we have to add the sample size of the group, which can be done through the use of the [`sum`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html) function on the `count` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4 # number of groups\n",
    "n = grouped_df['count'].sum() # total sample size across the groups\n",
    "\n",
    "print(\"Total number of groups (k): \", k)\n",
    "print(\"Total Sample Size across the groups (n): \", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we already have the value for *k* and *n*, we can calculate the Sum of Squares Total (SST) and  Sum of Squares Between Groups (SSG). This can be done with the use of [`for loop`](https://docs.python.org/3/tutorial/controlflow.html) of python since we need to iterate through the groups (for SSG) and through the observations (for SST). Although, the data set used for SST only includes the observations that are used for this research question, and not the original data set.\n",
    "\n",
    "The [`iloc`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html) function was used to easily get one whole observation from the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSG = 0\n",
    "SST = 0 \n",
    "for x in range (k):\n",
    "    temp = grouped_df.iloc[x]\n",
    "    SSG = SSG + float (temp [\"count\"]) * (float (temp [\"mean\"]) - overall_mean)**2\n",
    "\n",
    "print(\"SSG: \", SSG)\n",
    "\n",
    "for x in range (n):\n",
    "    temp = new_df.iloc[x]\n",
    "    SST = SST + float (overall_mean - temp [\"Rmax [TFlop/s]\"])**2\n",
    "    \n",
    "print(\"SST: \", SST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10: Calculating the Degree of Freedom\n",
    "For ANOVA, there are two degrees of freedom used: the degree of freedom within groups(*df2*) and the degree of freedom between groups(*df1*). These two values are to be used to look up the *p-value* from the F-table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = k - 1 \n",
    "df2 = n - k \n",
    "\n",
    "print (\"df1: \", df1)\n",
    "print (\"df2: \", df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 11: Calculating the Mean Squares\n",
    "After determining the *df1* and *df2*, we can continue on to calculating the mean squares. To calculate for the F-statistic value, we have to compute for the Mean Squared variation due to Groups (MSG) and the Mean Square Error (MSE) using their respective formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSG = 1/df1 * SSG\n",
    "MSE = 1/df2 * (SST - SSG)\n",
    "\n",
    "print (\"MSG: \", MSG)\n",
    "print (\"MSE: \", MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 12: Calculate the F - statistic\n",
    "The F-statistic value is also needed in order to get the p-value from the F-table. This value can be calculated by dividing the MSG by MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = MSG / MSE\n",
    "\n",
    "print (\"F - value: \", F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 13: Looking up the p-value from the F-table\n",
    "Using the F-table, *df1*, *df2* and the *F-value*, we were able to get the *p-value* of 6.023437432591796e-13 (**p-value = 6.023437432591796e-13**). However, we may also use scipy.stats as it has a built-in function that allows the computation for the F-statistic and the p-value. Using the [`f_oneway`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html) function, we can get the F-statistic value and the p-value, given the observations of the different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.f_oneway(data.loc[supercom_df[\"Segment\"] == 'Academic'][\"Rmax [TFlop/s]\"],\n",
    "               data.loc[supercom_df[\"Segment\"] == 'Government'][\"Rmax [TFlop/s]\"],\n",
    "               data.loc[supercom_df[\"Segment\"] == 'Industry'][\"Rmax [TFlop/s]\"],\n",
    "               data.loc[supercom_df[\"Segment\"] == 'Research'][\"Rmax [TFlop/s]\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value (6.023437432591796e-13) is less than the significance level (0.05), reject the null hypothesis. \n",
    "\n",
    "For comparison, we can also compute for the *p-value* of the original dataframe `supercom_df`. Note that we have not removed the outliers in this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.f_oneway(supercom_df.loc[supercom_df[\"Segment\"] == 'Academic'][\"Rmax [TFlop/s]\"],\n",
    "               supercom_df.loc[supercom_df[\"Segment\"] == 'Government'][\"Rmax [TFlop/s]\"],\n",
    "               supercom_df.loc[supercom_df[\"Segment\"] == 'Industry'][\"Rmax [TFlop/s]\"],\n",
    "               supercom_df.loc[supercom_df[\"Segment\"] == 'Research'][\"Rmax [TFlop/s]\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the two p-values that we have gotten from before and after removing the outliers in the dataframe for the value of `Rmax [TFlop/s]`, we can see that, in both versions, the null hypothesis would be rejected as the p-value is less than the significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of the `Processor Technology` preference of different `Segment` of the Industry\n",
    "\n",
    "#### Step 1: Deciding which Statistical Inference for Categorical Data method\n",
    "As our research question deals with determining if there is a significant relationship between two categorical variable, the Chi-square statistic can be used to answer this question. However, there are two conditions that our data set must pass in order to use this statistic: (1) the observations must be independent, and (2) there must be at least five samples each group.\n",
    "\n",
    "The observations in the data set are independent as they are not affected by each other. This means that an observation's values is not influenced by another observation. However, to count how many observations are within each group, we would need to use the [`agg`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = supercom_df.groupby(\"Segment\")\n",
    "grouped_df = grouped_df['Processor Technology'].agg(['count']).reset_index()\n",
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output of the [`agg`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html) function, we can see that each group has a sample size of at least five. This means that our data set passes the two conditions of using Chi-square statistics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Setting the Hypothesis\n",
    "\n",
    "$H_{0}$ (null hypothesis): There is no significant relationship between a supercomputer's `Process Technology` and the `Segment` of the industry it belongs in.\n",
    "\n",
    "$H_{A}$ (alternative hypothesis): There is a significant relationship between a supercomputer's `Process Technology` and the `Segment` of the industry it belongs in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Setting the Significance level\n",
    "Like in the previous research question, we would be setting the significant level to 0.05 ( = 0.05). This value would be our basis in accepting or rejecting the null hypothesis. Having a p-value less than or equal 0.05 would mean that there is a significant relationship between a supercomputer's `Process Technology` and the `Segment` of the industry it belongs in. On the other hand, when the p-value is greater than 0.05, it means that there is no significant relationship between the two categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Preparing the Two-way table\n",
    "In order to use the Chi-square statistic on our data, we need to prepare the table that would be used in the computation of the chi-statistic. Since we are looking for the relationship of two categorical variables, we would be creating a two-way table with the `Segment` groups being its column headers and the types of `Processor Technology` as its rows. \n",
    "\n",
    "Using the [`crosstab`](https://www.google.com/search?q=crosstab+pandas&rlz=1C1CHBF_enPH856PH856&oq=crosstab+pandas&aqs=chrome..69i57j0i512l6j0i390.4074j0j4&sourceid=chrome&ie=UTF-8) function, we were able to properly create the two-way table. In this function, the first parameter refers to what values are to be grouped by in the rows and the second parameter is for the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab = pd.crosstab(supercom_df['Processor Technology'], supercom_df['Segment'])\n",
    "print(crosstab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Computing for the Chi-statistic value and Getting its p-value\n",
    "Once we were able to derive the two-way table that holds the count of observation for each `Segment` that has each of the `Processor Technology`, we can move to computing for the chi-statistic value aand looking for its corresponding p-value. This can be done using the [`chi2_contingency`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html) function. This function returns the chi-statistic value, p-value and the degree of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.chi2_contingency(crosstab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [`chi2_contingency`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html) function, we were able to get the chi-statistic value of 308.5254186149681, the degree of freedom of our data set *85* and its p-value 4.143223560249361e-27."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Conclusion\n",
    "Since the p-value (4.143223560249361e-27) is less than the significance level (0.05), reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insights and Conclusions\n",
    "/* introduction */"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is there a significant difference between the means of the `Rmax [TFlop/s]` of the professional sectors?\n",
    "Since the p-value (6.02e-13) is less than the significance level (0.05), the null hypothesis is rejected. Thus, the data provided strong evidence that at least one of the group's mean `Rmax [TFlop/s]` deviates from the others under the significance level of 5%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is there a significant relationship between a supercomputer's `Processor Technology` and the `Segment` of the industry it belongs in?\n",
    "Since the p-value (4.14e-27) is less than the significance level, the null hypothesis is rejected. Thus, we can conclude that there is a statistically significant relationship between the variables `Processor Technology` and `Segment`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "*Chi Square | Practical Applications of Statistics in the Social Sciences* (n.d.). University of Southampton. Retrieved August 9, 2021, from https://www.southampton.ac.uk/passs/full_time_education/bivariate_analysis/chi_square.page\n",
    "\n",
    "*Frequent Asked Questions on the LINPACK Benchmark*. (2007, May 8). Netlib. http://www.netlib.org/utk/people/JackDongarra/faq-linpack.html#_Toc27885709\n",
    "\n",
    "*How to Perform Analysis of Variance (ANOVA) - Step By Step Procedure*. (2018, March 7). The Genius Blog. https://kindsonthegenius.com/blog/how-to-perform-analysis-of-variance-anova-step-by-step-procedure/\n",
    "\n",
    "*Identifying Outliers: IQR Method | STAT 200*. (n.d.). Penn State University. Retrieved August 9, 2021, from https://online.stat.psu.edu/stat200/lesson/3/3.2\n",
    "\n",
    "*Introduction and Objectives*. (n.d.). Top500. Retrieved August 9, 2021, from https://www.top500.org/project/introduction/\n",
    "\n",
    "Moffitt, C. (2018, October 8). *Pandas Crosstab Explained*. Practical Business Python. https://pbpython.com/pandas-crosstab.html\n",
    "\n",
    "*Understanding the Interquartile Range in Statistics*. (n.d.). ThoughtCo. Retrieved August 9, 2021, from https://www.thoughtco.com/what-is-the-interquartile-range-3126245"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
